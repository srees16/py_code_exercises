{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87066288-6f13-4bac-9b43-c8f1d6bfdcb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 432\u001b[0m\n\u001b[0;32m    427\u001b[0m     \u001b[38;5;66;03m#note that this is the only py file with complete stats calculation\u001b[39;00m\n\u001b[0;32m    431\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 432\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[1], line 417\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    414\u001b[0m \u001b[38;5;66;03m#downloading data\u001b[39;00m\n\u001b[0;32m    415\u001b[0m df\u001b[38;5;241m=\u001b[39myf\u001b[38;5;241m.\u001b[39mdownload(ticker,start\u001b[38;5;241m=\u001b[39mstdate,end\u001b[38;5;241m=\u001b[39meddate)\n\u001b[1;32m--> 417\u001b[0m trading_signals\u001b[38;5;241m=\u001b[39msignal_generation(df,heikin_ashi,stls)\n\u001b[0;32m    419\u001b[0m viz\u001b[38;5;241m=\u001b[39mtrading_signals[slicer:]\n\u001b[0;32m    420\u001b[0m plot(viz,ticker)\n",
      "Cell \u001b[1;32mIn[1], line 81\u001b[0m, in \u001b[0;36msignal_generation\u001b[1;34m(df, method, stls)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msignal_generation\u001b[39m(df,method,stls):\n\u001b[1;32m---> 81\u001b[0m     data\u001b[38;5;241m=\u001b[39mmethod(df)\n\u001b[0;32m     83\u001b[0m     data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msignals\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;66;03m#i use cumulated sum to check how many positions i have longed\u001b[39;00m\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;66;03m#i would ignore the exit signal prior if not holding positions\u001b[39;00m\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;66;03m#i also keep tracking how many long positions i have got\u001b[39;00m\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;66;03m#long signals cannot exceed the stop loss limit\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[1], line 52\u001b[0m, in \u001b[0;36mheikin_ashi\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m#initialize heikin ashi open\u001b[39;00m\n\u001b[0;32m     51\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHA open\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 52\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHA open\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m=\u001b[39mdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOpen\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m#heikin ashi open\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;28mlen\u001b[39m(df)):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Feb 15 20:48:35 2018\n",
    "\n",
    "@author: Administrator\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "#heikin ashi is a Japanese way to filter out the noise for momentum trading\n",
    "#it can prevent the occurrence of sideway chops\n",
    "#basically we do a few transformations on four key benchmarks - Open, Close, High, Low\n",
    "#apply some unique rules on ha Open, Close, High, Low to trade\n",
    "#details of heikin ashi indicators and rules can be found in the following link\n",
    "# https://quantiacs.com/Blog/Intro-to-Algorithmic-Trading-with-Heikin-Ashi.aspx\n",
    "\n",
    "#need to get yfinance package first\n",
    "#it changes its name from fix_yahoo_finance to yfinance, lol\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import scipy.integrate\n",
    "import scipy.stats\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "\n",
    "#Heikin Ashi has a unique method to filter out the noise\n",
    "#its open, close, high, low require a different approach\n",
    "#please refer to the website mentioned above\n",
    "def heikin_ashi(data):\n",
    "    \n",
    "    df=data.copy()\n",
    "    \n",
    "    df.reset_index(inplace=True)\n",
    "        \n",
    "    #heikin ashi close\n",
    "    df['HA close']=(df['Open']+df['Close']+df['High']+df['Low'])/4\n",
    "\n",
    "    #initialize heikin ashi open\n",
    "    df['HA open']=float(0)\n",
    "    df['HA open'][0]=df['Open'][0]\n",
    "\n",
    "    #heikin ashi open\n",
    "    for n in range(1,len(df)):\n",
    "        df.at[n,'HA open']=(df['HA open'][n-1]+df['HA close'][n-1])/2\n",
    "        \n",
    "    #heikin ashi high/low\n",
    "    temp=pd.concat([df['HA open'],df['HA close'],df['Low'],df['High']],axis=1)\n",
    "    df['HA high']=temp.apply(max,axis=1)\n",
    "    df['HA low']=temp.apply(min,axis=1)\n",
    "\n",
    "    del df['Adj Close']\n",
    "    del df['Volume']\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "#setting up signal generations\n",
    "#trigger conditions can be found from the website mentioned above\n",
    "#they kinda look like marubozu candles\n",
    "#there s a short strategy as well\n",
    "#the trigger condition of short strategy is the reverse of long strategy\n",
    "#you have to satisfy all four conditions to long/short\n",
    "#nevertheless, the exit signal only has three conditions\n",
    "def signal_generation(df,method,stls):\n",
    "        \n",
    "    data=method(df)\n",
    "    \n",
    "    data['signals']=0\n",
    "\n",
    "    #i use cumulated sum to check how many positions i have longed\n",
    "    #i would ignore the exit signal prior if not holding positions\n",
    "    #i also keep tracking how many long positions i have got\n",
    "    #long signals cannot exceed the stop loss limit\n",
    "    data['cumsum']=0\n",
    "\n",
    "    for n in range(1,len(data)):\n",
    "        \n",
    "        #long triggered\n",
    "        if (data['HA open'][n]>data['HA close'][n] and data['HA open'][n]==data['HA high'][n] and\n",
    "            np.abs(data['HA open'][n]-data['HA close'][n])>np.abs(data['HA open'][n-1]-data['HA close'][n-1]) and\n",
    "            data['HA open'][n-1]>data['HA close'][n-1]):\n",
    "            \n",
    "            data.at[n,'signals']=1\n",
    "            data['cumsum']=data['signals'].cumsum()\n",
    "\n",
    "\n",
    "            #accumulate too many longs\n",
    "            if data['cumsum'][n]>stls:\n",
    "                data.at[n,'signals']=0\n",
    "        \n",
    "        #exit positions\n",
    "        elif (data['HA open'][n]<data['HA close'][n] and data['HA open'][n]==data['HA low'][n] and \n",
    "        data['HA open'][n-1]<data['HA close'][n-1]):\n",
    "            \n",
    "            data.at[n,'signals']=-1\n",
    "            data['cumsum']=data['signals'].cumsum()\n",
    "        \n",
    "\n",
    "            #clear all longs\n",
    "            #if there are no long positions in my portfolio\n",
    "            #ignore the exit signal\n",
    "            if data['cumsum'][n]>0:\n",
    "                data.at[n,'signals']=-1*(data['cumsum'][n-1])\n",
    "\n",
    "            if data['cumsum'][n]<0:\n",
    "                data.at[n,'signals']=0\n",
    "                \n",
    "    return data\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "#since matplotlib remove the candlestick\n",
    "#plus we dont wanna install mpl_finance\n",
    "#we implement our own version\n",
    "#simply use fill_between to construct the bar\n",
    "#use line plot to construct high and low\n",
    "def candlestick(df,ax=None,titlename='',highcol='High',lowcol='Low',\n",
    "                opencol='Open',closecol='Close',xcol='Date',\n",
    "                colorup='r',colordown='g',**kwargs):  \n",
    "    \n",
    "    #bar width\n",
    "    #use 0.6 by default\n",
    "    dif=[(-3+i)/10 for i in range(7)]\n",
    "    \n",
    "    if not ax:\n",
    "        ax=plt.figure(figsize=(10,5)).add_subplot(111)\n",
    "    \n",
    "    #construct the bars one by one\n",
    "    for i in range(len(df)):\n",
    "        \n",
    "        #width is 0.6 by default\n",
    "        #so 7 data points required for each bar\n",
    "        x=[i+j for j in dif]\n",
    "        y1=[df[opencol].iloc[i]]*7\n",
    "        y2=[df[closecol].iloc[i]]*7\n",
    "\n",
    "        barcolor=colorup if y1[0]>y2[0] else colordown\n",
    "        \n",
    "        #no high line plot if open/close is high\n",
    "        if df[highcol].iloc[i]!=max(df[opencol].iloc[i],df[closecol].iloc[i]):\n",
    "            \n",
    "            #use generic plot to viz high and low\n",
    "            #use 1.001 as a scaling factor\n",
    "            #to prevent high line from crossing into the bar\n",
    "            plt.plot([i,i],\n",
    "                     [df[highcol].iloc[i],\n",
    "                      max(df[opencol].iloc[i],\n",
    "                          df[closecol].iloc[i])*1.001],c='k',**kwargs)\n",
    "    \n",
    "        #same as high\n",
    "        if df[lowcol].iloc[i]!=min(df[opencol].iloc[i],df[closecol].iloc[i]):             \n",
    "            \n",
    "            plt.plot([i,i],\n",
    "                     [df[lowcol].iloc[i],\n",
    "                      min(df[opencol].iloc[i],\n",
    "                          df[closecol].iloc[i])*0.999],c='k',**kwargs)\n",
    "        \n",
    "        #treat the bar as fill between\n",
    "        plt.fill_between(x,y1,y2,\n",
    "                         edgecolor='k',\n",
    "                         facecolor=barcolor,**kwargs)\n",
    "\n",
    "    #only show 5 xticks\n",
    "    plt.xticks(range(0,len(df),len(df)//5),df[xcol][0::len(df)//5].dt.date)\n",
    "    plt.title(titlename)\n",
    "    \n",
    "    \n",
    "#plotting the backtesting result\n",
    "def plot(df,ticker):    \n",
    "    \n",
    "    df.set_index(df['Date'],inplace=True)\n",
    "    \n",
    "    #first plot is Heikin-Ashi candlestick\n",
    "    #use candlestick function and set Heikin-Ashi O,C,H,L\n",
    "    ax1=plt.subplot2grid((200,1), (0,0), rowspan=120,ylabel='HA price')\n",
    "    candlestick(df,ax1,titlename='',highcol='HA high',lowcol='HA low',\n",
    "                opencol='HA open',closecol='HA close',xcol='Date',\n",
    "                colorup='r',colordown='g')\n",
    "    plt.grid(True)\n",
    "    plt.xticks([])\n",
    "    plt.title('Heikin-Ashi')\n",
    "\n",
    "\n",
    "    #the second plot is the actual price with long/short positions as up/down arrows\n",
    "    ax2=plt.subplot2grid((200,1), (120,0), rowspan=80,ylabel='price',xlabel='')\n",
    "    df['Close'].plot(ax=ax2,label=ticker)\n",
    "\n",
    "    #long/short positions are attached to the real close price of the stock\n",
    "    #set the line width to zero\n",
    "    #thats why we only observe markers\n",
    "    ax2.plot(df.loc[df['signals']==1].index,df['Close'][df['signals']==1],marker='^',lw=0,c='g',label='long')\n",
    "    ax2.plot(df.loc[df['signals']<0].index,df['Close'][df['signals']<0],marker='v',lw=0,c='r',label='short')\n",
    "\n",
    "    plt.grid(True)\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "#backtesting\n",
    "#initial capital 10k to calculate the actual pnl  \n",
    "#100 shares to buy of every position\n",
    "def portfolio(data,capital0=10000,positions=100):   \n",
    "        \n",
    "    #cumsum column is created to check the holding of the position\n",
    "    data['cumsum']=data['signals'].cumsum()\n",
    "\n",
    "    portfolio=pd.DataFrame()\n",
    "    portfolio['holdings']=data['cumsum']*data['Close']*positions\n",
    "    portfolio['cash']=capital0-(data['signals']*data['Close']*positions).cumsum()\n",
    "    portfolio['total asset']=portfolio['holdings']+portfolio['cash']\n",
    "    portfolio['return']=portfolio['total asset'].pct_change()\n",
    "    portfolio['signals']=data['signals']\n",
    "    portfolio['date']=data['Date']\n",
    "    portfolio.set_index('date',inplace=True)\n",
    "\n",
    "    return portfolio\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "#plotting the asset value change of the portfolio\n",
    "def profit(portfolio):\n",
    "        \n",
    "    fig=plt.figure()\n",
    "    bx=fig.add_subplot(111)\n",
    "    \n",
    "    portfolio['total asset'].plot(label='Total Asset')\n",
    "    \n",
    "    #long/short position markers related to the portfolio\n",
    "    #the same mechanism as the previous one\n",
    "    #replace close price with total asset value\n",
    "    bx.plot(portfolio['signals'].loc[portfolio['signals']==1].index,portfolio['total asset'][portfolio['signals']==1],lw=0,marker='^',c='g',label='long')\n",
    "    bx.plot(portfolio['signals'].loc[portfolio['signals']<0].index,portfolio['total asset'][portfolio['signals']<0],lw=0,marker='v',c='r',label='short')\n",
    "    \n",
    "    plt.legend(loc='best')\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Asset Value')\n",
    "    plt.title('Total Asset')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "#omega ratio is a variation of sharpe ratio\n",
    "#the risk free return is replaced by a given threshold\n",
    "#in this case, the return of benchmark\n",
    "#integral is needed to calculate the return above and below the threshold\n",
    "#you can use summation to do approximation as well\n",
    "#it is a more reasonable ratio to measure the risk adjusted return\n",
    "#normal distribution doesnt explain the fat tail of returns\n",
    "#so i use student T cumulated distribution function instead \n",
    "#to make our life easier, i do not use empirical distribution\n",
    "#the cdf of empirical distribution is much more complex\n",
    "#check wikipedia for more details\n",
    "# https://en.wikipedia.org/wiki/Omega_ratio\n",
    "def omega(risk_free,degree_of_freedom,maximum,minimum):\n",
    "\n",
    "    y=scipy.integrate.quad(lambda g:1-scipy.stats.t.cdf(g,degree_of_freedom),risk_free,maximum)\n",
    "    x=scipy.integrate.quad(lambda g:scipy.stats.t.cdf(g,degree_of_freedom),minimum,risk_free)\n",
    "\n",
    "    z=(y[0])/(x[0])\n",
    "\n",
    "    return z\n",
    "\n",
    "\n",
    "#sortino ratio is another variation of sharpe ratio\n",
    "#the standard deviation of all returns is substituted with standard deviation of negative returns\n",
    "#sortino ratio measures the impact of negative return on return\n",
    "#i am also using student T probability distribution function instead of normal distribution\n",
    "#check wikipedia for more details\n",
    "# https://en.wikipedia.org/wiki/Sortino_ratio\n",
    "def sortino(risk_free,degree_of_freedom,growth_rate,minimum):\n",
    "\n",
    "    v=np.sqrt(np.abs(scipy.integrate.quad(lambda g:((risk_free-g)**2)*scipy.stats.t.pdf(g,degree_of_freedom),risk_free,minimum)))\n",
    "    s=(growth_rate-risk_free)/v[0]\n",
    "\n",
    "    return s\n",
    "\n",
    "\n",
    "#i use a function to calculate maximum drawdown\n",
    "#the idea is simple\n",
    "#for every day, we take the current asset value marked to market\n",
    "#to compare with the previous highest asset value\n",
    "#we get our daily drawdown\n",
    "#it is supposed to be negative if the current one is not the highest\n",
    "#we implement a temporary variable to store the minimum negative value\n",
    "#which is called maximum drawdown\n",
    "#for each daily drawdown that is smaller than our temporary value\n",
    "#we update the temp until we finish our traversal\n",
    "#in the end we return the maximum drawdown\n",
    "def mdd(series):\n",
    "\n",
    "    minimum=0\n",
    "    for i in range(1,len(series)):\n",
    "        if minimum>(series[i]/max(series[:i])-1):\n",
    "            minimum=(series[i]/max(series[:i])-1)\n",
    "\n",
    "    return minimum\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "    \n",
    "\n",
    "#stats calculation\n",
    "def stats(portfolio,trading_signals,stdate,eddate,capital0=10000):\n",
    "\n",
    "    stats=pd.DataFrame([0])\n",
    "\n",
    "    #get the min and max of return\n",
    "    maximum=np.max(portfolio['return'])\n",
    "    minimum=np.min(portfolio['return'])    \n",
    "\n",
    "    #growth_rate denotes the average growth rate of portfolio \n",
    "    #use geometric average instead of arithmetic average for percentage growth\n",
    "    growth_rate=(float(portfolio['total asset'].iloc[-1]/capital0))**(1/len(trading_signals))-1\n",
    "\n",
    "    #calculating the standard deviation\n",
    "    std=float(np.sqrt((((portfolio['return']-growth_rate)**2).sum())/len(trading_signals)))\n",
    "\n",
    "    #use S&P500 as benchmark\n",
    "    benchmark=yf.download('^GSPC',start=stdate,end=eddate)\n",
    "\n",
    "    #return of benchmark\n",
    "    return_of_benchmark=float(benchmark['Close'].iloc[-1]/benchmark['Open'].iloc[0]-1)\n",
    "\n",
    "    #rate_of_benchmark denotes the average growth rate of benchmark \n",
    "    #use geometric average instead of arithmetic average for percentage growth\n",
    "    rate_of_benchmark=(return_of_benchmark+1)**(1/len(trading_signals))-1\n",
    "\n",
    "    del benchmark\n",
    "\n",
    "    #backtesting stats\n",
    "    #CAGR stands for cumulated average growth rate\n",
    "    stats['CAGR']=stats['portfolio return']=float(0)\n",
    "    stats['CAGR'][0]=growth_rate\n",
    "    stats['portfolio return'][0]=portfolio['total asset'].iloc[-1]/capital0-1\n",
    "    stats['benchmark return']=return_of_benchmark\n",
    "    stats['sharpe ratio']=(growth_rate-rate_of_benchmark)/std\n",
    "    stats['maximum drawdown']=mdd(portfolio['total asset'])\n",
    "\n",
    "    #calmar ratio is sorta like sharpe ratio\n",
    "    #the standard deviation is replaced by maximum drawdown\n",
    "    #it is the measurement of return after worse scenario adjustment\n",
    "    #check wikipedia for more details\n",
    "    # https://en.wikipedia.org/wiki/Calmar_ratio\n",
    "    stats['calmar ratio']=growth_rate/stats['maximum drawdown']\n",
    "    stats['omega ratio']=omega(rate_of_benchmark,len(trading_signals),maximum,minimum)\n",
    "    stats['sortino ratio']=sortino(rate_of_benchmark,len(trading_signals),growth_rate,minimum)\n",
    "\n",
    "    #note that i use stop loss limit to limit the numbers of longs\n",
    "    #and when clearing positions, we clear all the positions at once\n",
    "    #so every long is always one, and short cannot be larger than the stop loss limit\n",
    "    stats['numbers of longs']=trading_signals['signals'].loc[trading_signals['signals']==1].count()\n",
    "    stats['numbers of shorts']=trading_signals['signals'].loc[trading_signals['signals']<0].count()\n",
    "    stats['numbers of trades']=stats['numbers of shorts']+stats['numbers of longs']  \n",
    "\n",
    "    #to get the total length of trades\n",
    "    #given that cumsum indicates the holding of positions\n",
    "    #we can get all the possible outcomes when cumsum doesnt equal zero\n",
    "    #then we count how many non-zero positions there are\n",
    "    #we get the estimation of total length of trades\n",
    "    stats['total length of trades']=trading_signals['signals'].loc[trading_signals['cumsum']!=0].count()\n",
    "    stats['average length of trades']=stats['total length of trades']/stats['numbers of trades']\n",
    "    stats['profit per trade']=float(0)\n",
    "    stats['profit per trade'].iloc[0]=(portfolio['total asset'].iloc[-1]-capital0)/stats['numbers of trades'].iloc[0]\n",
    "\n",
    "    del stats[0]\n",
    "    print(stats)\n",
    "\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "def main():\n",
    "    \n",
    "    #initializing\n",
    "\n",
    "    #stop loss positions, the maximum long positions we can get\n",
    "    #without certain constraints, you will long indefinites times \n",
    "    #as long as the market condition triggers the signal\n",
    "    #in a whipsaw condition, it is suicidal\n",
    "    stls=3\n",
    "    ticker='NVDA'\n",
    "    stdate='2015-04-01'\n",
    "    eddate='2018-02-15'\n",
    "\n",
    "    #slicer is used for plotting\n",
    "    #a three year dataset with 750 data points would be too much\n",
    "    slicer=700\n",
    "\n",
    "    #downloading data\n",
    "    df=yf.download(ticker,start=stdate,end=eddate)\n",
    "\n",
    "    trading_signals=signal_generation(df,heikin_ashi,stls)\n",
    "\n",
    "    viz=trading_signals[slicer:]\n",
    "    plot(viz,ticker)\n",
    "\n",
    "    portfolio_details=portfolio(viz)\n",
    "    profit(portfolio_details)\n",
    "\n",
    "    stats(portfolio_details,trading_signals,stdate,eddate)\n",
    "\n",
    "    #note that this is the only py file with complete stats calculation\n",
    "    \n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75feac2-d62a-4358-be62-f40b740256d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
